import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
import streamlit as st 
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
import pandas as pd 
import joblib

st.set_page_config(
    page_title="Projet Temp√©rature",
    page_icon="üëã",
    layout="wide",
)

st.markdown("# Exploration des donn√©es")
st.sidebar.header("Exploration des donn√©es")
footer="""<style>
a:link , a:visited{
color: blue;
background-color: transparent;
text-decoration: underline;
}

a:hover,  a:active {
color: red;
background-color: transparent;
text-decoration: underline;
}

.footer {
position: fixed;
left: 0;
bottom: 0;
width: 100%;
background-color: white;
color: black;
text-align: center;
}
</style>
<div class="footer">
<p>Developed with ‚ù§ by Yves Roig</p>
</div>
"""
st.markdown(footer,unsafe_allow_html=True)

pages = ["Entrainement", "Spearman et Pearson", "Pr√©diction"]
page = st.sidebar.radio("Aller vers la page :", pages)

df_anoIncTemp = pd.read_csv('data/Anomalies Incertitude Temperature.csv', sep = ';')

if page == pages[0]:
    # Liste des mod√®les
    model_of_interest = ['Decision tree', 'Random forest', 'XGBRegressor', 'Lasso', 'Ridge', 'Linear regression']

    select1, select2 = st.columns(2)
    with select1:
        # S√©lection des mod√®les √† afficher
        selected_models = st.multiselect('S√©lectionnez un des mod√®les :', model_of_interest, default='Linear regression')
    with select2:
        selected_date = st.selectbox("S√©lectionner la date de d√©but :", [1950, 1980]) 

    # Divisez les donn√©es en ensembles d'entra√Ænement et de test
    train_data = df_anoIncTemp[(df_anoIncTemp['year'] >= selected_date) & (df_anoIncTemp['year'] <= 2010)]
    test_data = df_anoIncTemp[(df_anoIncTemp['year'] >= 2011) & (df_anoIncTemp['year'] <= 2021)]

    # S√©parez les caract√©ristiques (X) de la cible (y) pour l'entra√Ænement
    X_train = np.array(train_data['year']).reshape(-1, 1)
    y_train = train_data['anomalie']

    # S√©parez les caract√©ristiques (X) de la cible (y) pour le test
    X_test = np.array(test_data['year']).reshape(-1, 1)
    y_test = test_data['anomalie']

    # Mod√®le de r√©gression lin√©aire
    linear_model = joblib.load(f"models/linear_regression_{selected_date}")
    linear_predictions = linear_model.predict(X_test)

    # Mod√®le Ridge
    ridge_model = joblib.load(f"models/ridge_{selected_date}")
    ridge_predictions = ridge_model.predict(X_test)

    lasso_model = joblib.load(f"models/lasso_{selected_date}")
    lasso_predictions = lasso_model.predict(X_test)

    # Mod√®le Decision Tree Regressor
    dt_model = joblib.load(f"models/TreeRegressor_{selected_date}")
    dt_predictions = dt_model.predict(X_test)

    # Mod√®le Random Forest Regressor
    rf_model = joblib.load(f"models/random_forest_{selected_date}")
    rf_predictions = rf_model.predict(X_test)

    # Mod√®le XGBRegressor
    xgb_model = joblib.load(f"models/XGBRegressor_{selected_date}")
    xgb_predictions = xgb_model.predict(X_test)

    col1, col2 = st.columns([2,1])

    fig, ax = plt.subplots(figsize=(20, 12))  # Ajuster la taille du graphique
    ax.scatter(train_data['year'], train_data['anomalie'], color='blue', label='Donn√©es d\'entra√Ænement')
    ax.scatter(test_data['year'], test_data['anomalie'], color='red', label='Donn√©es de test')
    erreurs_quadratiques = {}
    for model in selected_models:
        if model == "Decision tree":
            predictions = dt_predictions
            label="Pr√©dictions Decision Tree"
            dt_mse = mean_squared_error(y_test, dt_predictions)
            erreurs_quadratiques["Decision Tree :"] = dt_mse
        elif model == 'Random forest':
            predictions = rf_predictions
            label="Pr√©dictions Random forest"
            rf_mse = mean_squared_error(y_test, rf_predictions)
            erreurs_quadratiques["Random Forest :"] = rf_mse
        elif model == 'XGBRegressor':
            predictions = xgb_predictions
            label="Pr√©dictions XGBRegressor"
            xgb_mse = mean_squared_error(y_test, xgb_predictions)
            erreurs_quadratiques["XGBRegressor :"] = xgb_mse
        elif model == "Linear regression":
            predictions = linear_predictions
            label="Pr√©dictions Linear regression"
            # √âvaluer les performances du mod√®le sur les donn√©es de test
            linear_mse = mean_squared_error(test_data['anomalie'], linear_predictions)
            erreurs_quadratiques["R√©gression Lin√©aire :"] = linear_mse
        elif model == "Ridge":
            predictions = ridge_predictions
            label="Pr√©dictions Ridge"
            ridge_mse = mean_squared_error(test_data['anomalie'], ridge_predictions)
            erreurs_quadratiques["Ridge :"] = ridge_mse
        elif model == "Lasso":
            predictions = lasso_predictions
            label="Pr√©dictions Lasso"
            lasso_mse = mean_squared_error(test_data['anomalie'], lasso_predictions)
            erreurs_quadratiques["Lasso :"] = lasso_mse

        ax.plot(test_data['year'], predictions, label=label)
        plt.title('Pr√©dictions pour les anomalies de temp√©rature')

    with col1:
        ax.set_xlabel('Ann√©e')
        ax.set_ylabel('Anomalie de temp√©rature')
        ax.legend()
        ax.grid(True)
        st.pyplot(fig)

    with col2:
        st.write("## Erreurs quadratiques des mod√®les")
        colName, colResult = st.columns([2, 7])
        for erreurs_quadratique in erreurs_quadratiques.keys():
            with colName:
                st.write(erreurs_quadratique)
            with colResult:
                st.write(erreurs_quadratiques[erreurs_quadratique])

elif page == pages[1]:
    from scipy.stats import spearmanr
    from sklearn.linear_model import LinearRegression
    from scipy.stats import pearsonr

    df_co2 = pd.read_csv('data/CO2 Donnees.csv', sep=',')
    df_filtered = df_co2[(df_co2['iso_code'].notna()) & (df_co2['year'] >= 1850) & (df_co2['year'] <= 2018)]
    # Groupby par ann√©e et sum pour obtenir la somme de co2_including_luc et de la population pour chaque ann√©e
    df_sum_co2_population = df_filtered.groupby('year')[['co2_including_luc', 'population']].sum().reset_index()

    df_filtered = df_co2[(df_co2['iso_code'].notna()) & (df_co2['year'] >= 1850) & (df_co2['year'] <= 2021)]
    df_sum_co2 = df_filtered.groupby('year')['co2_including_luc'].sum().reset_index()

    # Supposons que df_sum_co2 contienne les donn√©es de la somme du CO2 et df_anoIncTemp contienne les donn√©es de l'anomalie de temp√©rature
    # Assurez-vous que ces DataFrames sont correctement d√©finis avec les colonnes 'year' et les valeurs correspondantes.

    # Fusionner les deux DataFrames sur la colonne 'year'
    df_merged = pd.merge(df_sum_co2, df_anoIncTemp, on='year', how='inner')

    # Calculer la corr√©lation de Spearman
    correlation_coefficient, p_value = spearmanr(df_merged['co2_including_luc'], df_merged['anomalie'])

    # Afficher les r√©sultats
    st.write(f"Corr√©lation de Spearman : {correlation_coefficient}")
    st.write(f"P-value : {p_value}")
    # Interpr√©tation du r√©sultat
    if p_value < 0.05:
        st.write("La corr√©lation est statistiquement significative.")
    else:
        st.write("La corr√©lation n'est pas statistiquement significative.")

    # Supposons que df_sum_co2 contienne les donn√©es de la somme du CO2 et df_anoIncTemp contienne les donn√©es de l'anomalie de temp√©rature
    # Assurez-vous que ces DataFrames sont correctement d√©finis avec les colonnes 'year' et les valeurs correspondantes.

    # Fusionner les deux DataFrames sur la colonne 'year'
    df_merged = pd.merge(df_sum_co2, df_anoIncTemp, on='year', how='inner')

    # S√©parer les caract√©ristiques (X) de la cible (y)
    X = df_merged[['co2_including_luc']]
    y = df_merged['anomalie']

    # Cr√©er et entra√Æner le mod√®le de r√©gression lin√©aire
    linear_model = LinearRegression()
    linear_model.fit(X, y)

    # Calculer la corr√©lation de Spearman entre les pr√©dictions du mod√®le et la cible
    predictions = linear_model.predict(X)
    correlation_coefficient, p_value = spearmanr(predictions, y)

    # Afficher les r√©sultats
    st.write(f"Corr√©lation de Spearman avec la r√©gression lin√©aire : {correlation_coefficient}")
    st.write(f"P-value : {p_value}")

    # Interpr√©tation du r√©sultat
    if p_value < 0.05:
        st.write("La corr√©lation est statistiquement significative.")
    else:
        st.write("La corr√©lation n'est pas statistiquement significative.")



    # S√©lectionner les donn√©es pour la p√©riode sp√©cifi√©e
    df_selected = df_sum_co2_population[(df_sum_co2_population['year'] >= 1850) & (df_sum_co2_population['year'] <= 2018)]

    # Calculer la corr√©lation de Pearson
    correlation, p_value = pearsonr(df_selected['co2_including_luc'], df_selected['population'])

    # Afficher le r√©sultat
    st.write(f"Corr√©lation de Pearson : {correlation}")
    st.write(f"Valeur de p : {p_value}")

    # Interpr√©tation du r√©sultat
    if p_value < 0.05:
        st.write("La corr√©lation est statistiquement significative.")
    else:
        st.write("La corr√©lation n'est pas statistiquement significative.")

else:

    selected_date = st.selectbox("S√©lectionner la date de d√©but :", [2050, 2073, 2100]) 
    prohet_predictions = joblib.load(f'predictions/prophet_{selected_date}')

    colYhat, colTrend = st.columns(2)
    with colYhat:
        fig = plt.figure(figsize=(20, 10))
        plt.plot(prohet_predictions['ds'], prohet_predictions['yhat'], label='yhat')

        if st.checkbox("Prediction Yhat + Incertitude", True) : 
            plt.plot(prohet_predictions['ds'], prohet_predictions['yhat_upper'], label='Prediction + Incertitude', color="darkred")
            plt.fill_between(prohet_predictions['ds'], prohet_predictions['yhat'], prohet_predictions['yhat_upper'], color='pink')

        if st.checkbox("predictions Yhat - Incertitude", True): 
            plt.plot(prohet_predictions['ds'], prohet_predictions['yhat_lower'], label='Prediction - Incertitude', color="darkred")
            plt.fill_between(prohet_predictions['ds'], prohet_predictions['yhat'], prohet_predictions['yhat_lower'], color='pink')

    
        plt.xticks(pd.date_range(start=prohet_predictions["ds"].min(), end=prohet_predictions["ds"].max(), freq='10Y'), pd.date_range(start=prohet_predictions["ds"].min(), end=prohet_predictions["ds"].max(), freq='10Y', inclusive='both').year)
        plt.grid(True)
        st.pyplot(fig)

    with colTrend:
        fig = plt.figure(figsize=(20, 10))
        plt.plot(prohet_predictions['ds'], prohet_predictions['trend'], label='trend')
        
        if st.checkbox("Prediction Trend + Incertitude", True) : 
            plt.plot(prohet_predictions['ds'], prohet_predictions['trend_upper'], label='Prediction + Incertitude', color="darkred")
            plt.fill_between(prohet_predictions['ds'], prohet_predictions['trend'], prohet_predictions['trend_upper'], color='pink')

        if st.checkbox("predictions Trend - Incertitude", True): 
            plt.plot(prohet_predictions['ds'], prohet_predictions['trend_lower'], label='Prediction - Incertitude', color="darkred")
            plt.fill_between(prohet_predictions['ds'], prohet_predictions['trend'], prohet_predictions['trend_lower'], color='pink')

    
        plt.xticks(pd.date_range(start=prohet_predictions["ds"].min(), end=prohet_predictions["ds"].max(), freq='10Y'), pd.date_range(start=prohet_predictions["ds"].min(), end=prohet_predictions["ds"].max(), freq='10Y', inclusive='both').year)
        plt.grid(True)
        st.pyplot(fig)

    
    st.write(prohet_predictions)