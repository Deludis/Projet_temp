import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
import streamlit as st 
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
import pandas as pd 
import joblib

st.set_page_config(
    page_title="Projet Temp√©rature",
    page_icon="üëã",
    layout="wide",
)

st.markdown("# Pr√©visions")
st.sidebar.header("Pr√©visions")
footer="""<style>
a:link , a:visited{
color: blue;
background-color: transparent;
text-decoration: underline;
}

a:hover,  a:active {
color: red;
background-color: transparent;
text-decoration: underline;
}

.footer {
position: fixed;
left: 0;
bottom: 0;
width: 100%;
background-color: white;
color: black;
text-align: center;
}
</style>
<div class="footer">
<p>Developed with ‚ù§ by Yves Roig</p>
</div>
"""
st.markdown(footer,unsafe_allow_html=True)

pages = ["Entrainements", "Corr√©lations", "Pr√©dictions"]
page = st.sidebar.radio("Aller vers la page :", pages)

df_anoIncTemp = pd.read_csv('data/Anomalies Incertitude Temperature.csv', sep = ';')

if page == pages[0]:
    st.write("### Entrainements et tests (1950 et 1980)")
    # Liste des mod√®les
    model_of_interest = ['Decision tree', 'Random forest', 'XGBRegressor', 'Lasso', 'Ridge', 'Linear regression']

    select1, select2 = st.columns(2)
    with select1:
        # S√©lection des mod√®les √† afficher
        selected_models = st.multiselect('S√©lectionnez un des mod√®les :', model_of_interest, default='Linear regression')
    with select2:
        selected_date = st.selectbox("S√©lectionner la date de d√©but :", [1950, 1980]) 

    # Divisez les donn√©es en ensembles d'entra√Ænement et de test
    train_data = df_anoIncTemp[(df_anoIncTemp['year'] >= selected_date) & (df_anoIncTemp['year'] <= 2010)]
    test_data = df_anoIncTemp[(df_anoIncTemp['year'] >= 2011) & (df_anoIncTemp['year'] <= 2021)]

    # S√©parez les caract√©ristiques (X) de la cible (y) pour l'entra√Ænement
    X_train = np.array(train_data['year']).reshape(-1, 1)
    y_train = train_data['anomalie']

    # S√©parez les caract√©ristiques (X) de la cible (y) pour le test
    X_test = np.array(test_data['year']).reshape(-1, 1)
    y_test = test_data['anomalie']

    # Mod√®le de r√©gression lin√©aire
    linear_model = joblib.load(f"models/linear_regression_{selected_date}")
    linear_predictions = linear_model.predict(X_test)

    # Mod√®le Ridge
    ridge_model = joblib.load(f"models/ridge_{selected_date}")
    ridge_predictions = ridge_model.predict(X_test)

    lasso_model = joblib.load(f"models/lasso_{selected_date}")
    lasso_predictions = lasso_model.predict(X_test)

    # Mod√®le Decision Tree Regressor
    dt_model = joblib.load(f"models/TreeRegressor_{selected_date}")
    dt_predictions = dt_model.predict(X_test)

    # Mod√®le Random Forest Regressor
    rf_model = joblib.load(f"models/random_forest_{selected_date}")
    rf_predictions = rf_model.predict(X_test)

    # Mod√®le XGBRegressor
    xgb_model = joblib.load(f"models/XGBRegressor_{selected_date}")
    xgb_predictions = xgb_model.predict(X_test)

    col1, col2 = st.columns([2,1])

    fig, ax = plt.subplots(figsize=(20, 12))  # Ajuster la taille du graphique
    ax.scatter(train_data['year'], train_data['anomalie'], color='blue', label='Donn√©es d\'entra√Ænement')
    ax.scatter(test_data['year'], test_data['anomalie'], color='red', label='Donn√©es de test')
    erreurs_quadratiques = {}
    for model in selected_models:
        if model == "Decision tree":
            predictions = dt_predictions
            label="Pr√©dictions Decision Tree"
            dt_mse = mean_squared_error(y_test, dt_predictions)
            erreurs_quadratiques["Decision Tree :"] = dt_mse
        elif model == 'Random forest':
            predictions = rf_predictions
            label="Pr√©dictions Random forest"
            rf_mse = mean_squared_error(y_test, rf_predictions)
            erreurs_quadratiques["Random Forest :"] = rf_mse
        elif model == 'XGBRegressor':
            predictions = xgb_predictions
            label="Pr√©dictions XGBRegressor"
            xgb_mse = mean_squared_error(y_test, xgb_predictions)
            erreurs_quadratiques["XGBRegressor :"] = xgb_mse
        elif model == "Linear regression":
            predictions = linear_predictions
            label="Pr√©dictions Linear regression"
            # √âvaluer les performances du mod√®le sur les donn√©es de test
            linear_mse = mean_squared_error(test_data['anomalie'], linear_predictions)
            erreurs_quadratiques["R√©gression Lin√©aire :"] = linear_mse
        elif model == "Ridge":
            predictions = ridge_predictions
            label="Pr√©dictions Ridge"
            ridge_mse = mean_squared_error(test_data['anomalie'], ridge_predictions)
            erreurs_quadratiques["Ridge :"] = ridge_mse
        elif model == "Lasso":
            predictions = lasso_predictions
            label="Pr√©dictions Lasso"
            lasso_mse = mean_squared_error(test_data['anomalie'], lasso_predictions)
            erreurs_quadratiques["Lasso :"] = lasso_mse

        ax.plot(test_data['year'], predictions, label=label)
        plt.title('Pr√©dictions pour les anomalies de temp√©rature', fontsize=30)

    with col1:
        ax.set_xlabel('Ann√©e', fontsize=30)
        ax.set_ylabel('Anomalie de temp√©rature', fontsize=30)
        ax.legend(fontsize=20)
        ax.grid(True)
        st.pyplot(fig)

    with col2:
        st.write("## Erreurs quadratiques des mod√®les")
        colName, colResult = st.columns([2, 7])
        for erreurs_quadratique in erreurs_quadratiques.keys():
            with colName:
                st.write(erreurs_quadratique)
            with colResult:
                st.write(erreurs_quadratiques[erreurs_quadratique])
                
    st.write("### Nous allons entrainer 6 diff√©rents mod√®les avec deux ann√©es de d√©part : 1950 - 1980.")  
    st.write("### Les dur√©es de tests iront, respectivement, de 1950 √† 2010 et de 1980 √† 2010 et les trains de 2011 √† 2021 dans les 2 cas.")
    st.write("### Ceci nous permettra de voir si une p√©riode de test plus longue deviendrait plus pertinente.") 
    st.write("")
    st.write("### Les meilleurs r√©sultats sont obtenus avec la Linear Regression avec un d√©part en 1980")
    st.write("#### Il est important de noter que le MSE est sensible aux valeurs aberrantes (outliers), car les carr√©s accentuent davantage les erreurs importantes.")
    st.write("#### Nous avons donc pris le parti de tenir compte des valeurs aberrantes, compte tenu de l'objet de l'√©tude. Nous vivons tous actuellement, avec plus ou moins de force avec ces valeurs.")            

elif page == pages[1]:
    st.write("## Spearman, Pearson et P-Value ?")
    from scipy.stats import spearmanr
    from sklearn.linear_model import LinearRegression
    from scipy.stats import pearsonr

    df_co2 = pd.read_csv('data/CO2 Donnees.csv', sep=',')
    df_filtered = df_co2[(df_co2['iso_code'].notna()) & (df_co2['year'] >= 1850) & (df_co2['year'] <= 2018)]
    # Groupby par ann√©e et sum pour obtenir la somme de co2_including_luc et de la population pour chaque ann√©e
    df_sum_co2_population = df_filtered.groupby('year')[['co2_including_luc', 'population']].sum().reset_index()

    df_filtered = df_co2[(df_co2['iso_code'].notna()) & (df_co2['year'] >= 1850) & (df_co2['year'] <= 2021)]
    df_sum_co2 = df_filtered.groupby('year')['co2_including_luc'].sum().reset_index()

    
    # Fusionner les deux DataFrames sur la colonne 'year'
    df_merged = pd.merge(df_sum_co2, df_anoIncTemp, on='year', how='inner')

    # Calculer la corr√©lation de Spearman
    correlation_coefficient, p_value = spearmanr(df_merged['co2_including_luc'], df_merged['anomalie'])

    # Afficher les r√©sultats
    st.write(f"### Corr√©lation de Spearman = {correlation_coefficient}")
    st.write(f"### P-value = {p_value}")
    # Interpr√©tation du r√©sultat
    if p_value < 0.05:
        st.write("#### La corr√©lation est statistiquement significative.")
    else:
        st.write("#### La corr√©lation n'est pas statistiquement significative.")

    st.write("")
    st.write("")
 
    # Fusionner les deux DataFrames sur la colonne 'year'
    #df_merged = pd.merge(df_sum_co2, df_anoIncTemp, on='year', how='inner')

    # S√©parer les caract√©ristiques (X) de la cible (y)
    #X = df_merged[['co2_including_luc']]
    #y = df_merged['anomalie']

    # Cr√©er et entra√Æner le mod√®le de r√©gression lin√©aire
    #linear_model = LinearRegression()
    #linear_model.fit(X, y)

    # Calculer la corr√©lation de Spearman entre les pr√©dictions du mod√®le et la cible
    #predictions = linear_model.predict(X)
    #correlation_coefficient, p_value = spearmanr(predictions, y)

    # Afficher les r√©sultats
    #st.write(f"Corr√©lation de Spearman avec la r√©gression lin√©aire : {correlation_coefficient}")
    #st.write(f"P-value : {p_value}")
    
    
    # Interpr√©tation du r√©sultat
    #if p_value < 0.05:
        #st.write("La corr√©lation est statistiquement significative.")
    #else:
       # st.write("La corr√©lation n'est pas statistiquement significative.")
    


    # S√©lectionner les donn√©es pour la p√©riode sp√©cifi√©e
    df_selected = df_sum_co2_population[(df_sum_co2_population['year'] >= 1850) & (df_sum_co2_population['year'] <= 2018)]

    # Calculer la corr√©lation de Pearson
    correlation, p_value = pearsonr(df_selected['co2_including_luc'], df_selected['population'])

    # Afficher le r√©sultat
    st.write(f"### Corr√©lation de Pearson = {correlation}")
    st.write(f"### P-Value = {p_value}")

    # Interpr√©tation du r√©sultat
    if p_value < 0.05:
        st.write("#### La corr√©lation est statistiquement significative.")
    else:
        st.write("#### La corr√©lation n'est pas statistiquement significative.")
    st.write("")
    st.write("")
     
    st.write("#### Le choix entre Pearson et Spearman d√©pend de la nature de la relation entre les variables. Si la relation est lin√©aire, Pearson peut √™tre plus appropri√©. Si la relation n'est pas n√©cessairement lin√©aire, Spearman peut √™tre pr√©f√©r√©. La valeur P aide √† √©valuer la significativit√© statistique de la corr√©lation observ√©e.")
    st.write("#### Pearson semble plus adapt√© pour souligner la corr√©laton entre la population et les √©missions de CO2 (1850 -2018).")



else:
    st.write("### Pr√©dictions")
    selected_date = st.selectbox("S√©lectionner la date de d√©but :", [2050, 2073, 2100]) 
    prohet_predictions = joblib.load(f'predictions/prophet_{selected_date}')

    colYhat, colTrend = st.columns(2)
    with colYhat:
        fig = plt.figure(figsize=(20, 10))
        plt.plot(prohet_predictions['ds'], prohet_predictions['yhat'], label='yhat')

        if st.checkbox("Predictions Yhat Valeur Haute", True) : 
            plt.plot(prohet_predictions['ds'], prohet_predictions['yhat_upper'], label='Prediction + Incertitude', color="darkred")
            plt.fill_between(prohet_predictions['ds'], prohet_predictions['yhat'], prohet_predictions['yhat_upper'], color='pink')

        if st.checkbox("predictions Yhat Valeur Basse", True): 
            plt.plot(prohet_predictions['ds'], prohet_predictions['yhat_lower'], label='Prediction - Incertitude', color="darkred")
            plt.fill_between(prohet_predictions['ds'], prohet_predictions['yhat'], prohet_predictions['yhat_lower'], color='pink')

    
        plt.xticks(pd.date_range(start=prohet_predictions["ds"].min(), end=prohet_predictions["ds"].max(), freq='10Y'), pd.date_range(start=prohet_predictions["ds"].min(), end=prohet_predictions["ds"].max(), freq='10Y', inclusive='both').year)
        plt.grid(True)
        st.pyplot(fig)

    with colTrend:
        fig = plt.figure(figsize=(20, 10))
        plt.plot(prohet_predictions['ds'], prohet_predictions['trend'], label='trend')
        
        if st.checkbox("Predictions Trend Valeur Haute", True) : 
            plt.plot(prohet_predictions['ds'], prohet_predictions['trend_upper'], label='Prediction + Incertitude', color="darkred")
            plt.fill_between(prohet_predictions['ds'], prohet_predictions['trend'], prohet_predictions['trend_upper'], color='pink')

        if st.checkbox("predictions Trend Valeur Basse", True): 
            plt.plot(prohet_predictions['ds'], prohet_predictions['trend_lower'], label='Prediction - Incertitude', color="darkred")
            plt.fill_between(prohet_predictions['ds'], prohet_predictions['trend'], prohet_predictions['trend_lower'], color='pink')

    
        plt.xticks(pd.date_range(start=prohet_predictions["ds"].min(), end=prohet_predictions["ds"].max(), freq='10Y'), pd.date_range(start=prohet_predictions["ds"].min(), end=prohet_predictions["ds"].max(), freq='10Y', inclusive='both').year)
        plt.grid(True)
        st.pyplot(fig)

    
    st.write(prohet_predictions)
    st.write("")
    st.write("### Pr√©dictions Trend et Yhat √† l'horizon :") 
    st.write("#### 2050 : T + 1.5384  et  Y + 1.2578")
    st.write("#### 2073 : T + 1.8881  et  Y + 1.5153")
    st.write("#### 2100 : T + 2.2987  et  Y + 1.9563")
    st.write("")
    
    st.write("#### La TENDANCE dans Prophet repr√©sente la composante de la s√©rie temporelle qui capture la direction g√©n√©rale de l'√©volution des donn√©es au fil du temps. C'est la tendance globale, g√©n√©ralement repr√©sent√©e par une ligne droite, qui indique la direction dans laquelle les donn√©es √©voluent.")
    st.write("#### Le YHAT est la notation couramment utilis√©e pour repr√©senter les valeurs pr√©dites par le mod√®le de s√©ries temporelles. En d'autres termes, il s'agit des valeurs pr√©vues de la s√©rie temporelle pour chaque point temporel.")  
      
    
st.write("") 
st.write("")

st.markdown('<p style="color: red; font-size: 20px;">Tous les mod√®les ont √©t√© sauvegard√©s dans Models_generator.py et gr√¢ce √† joblib cela nous √©vite de les relancer √† chaque changement de page.</p>', unsafe_allow_html=True)
   